"""
CSV Data Loader for Augmented NeoDataset

Loads user story data from augmented NeoDataset CSV files generated by
the weak supervision pipeline (scripts/augment_neodataset.py).
"""
import pandas as pd
import os
from typing import List, Optional

from config import NEODATASET_PATH, NEODATASET_HIGH_CONF_PATH
from src.models.story import Story


class CSVDataLoader:
    """
    CSV implementation of data loader for augmented NeoDataset.
    This is the primary data source for SprintGuard.
    """
    
    def __init__(self, csv_path: str = NEODATASET_PATH, high_conf_only: bool = False):
        """
        Initialize CSV data loader.
        
        Args:
            csv_path: Path to augmented NeoDataset CSV
            high_conf_only: If True, use only high-confidence subset
        """
        if high_conf_only:
            csv_path = NEODATASET_HIGH_CONF_PATH
        
        self.csv_path = csv_path
        self._df = None
        self._load_data()
    
    def _load_data(self):
        """Load data from CSV file"""
        if not os.path.exists(self.csv_path):
            raise FileNotFoundError(
                f"\n{'='*70}\n"
                f"ERROR: Augmented NeoDataset not found at:\n"
                f"  {self.csv_path}\n\n"
                f"Please run the augmentation pipeline first:\n"
                f"  1. Install ML dependencies: pip install -r requirements-ml.txt\n"
                f"  2. Run augmentation: python scripts/augment_neodataset.py\n"
                f"{'='*70}\n"
            )
        
        self._df = pd.read_csv(self.csv_path)
        print(f"âœ“ Loaded {len(self._df)} stories from {os.path.basename(self.csv_path)}")
    
    def _row_to_story(self, row) -> Story:
        """Convert CSV row (pandas Series) to Story object"""
        return Story(
            id=int(row.get('id', row.name)),  # Use index if no id column
            description=row.get('description', ''),
            estimated_points=int(row.get('story_points', 0)) if pd.notna(row.get('story_points')) else None,
            actual_points=int(row.get('story_points', 0)) if pd.notna(row.get('story_points')) else None,
            days_to_complete=None,  # Not in NeoDataset
            caused_spillover=None,  # Not in NeoDataset
            risk_level=row.get('risk_label', 'Unknown'),  # From augmentation
            epic=None,
            reporter=None
        )
    
    def get_all_stories(self) -> List[Story]:
        """Retrieve all historical stories"""
        return [self._row_to_story(row) for _, row in self._df.iterrows()]
    
    def get_story_by_id(self, story_id: int) -> Optional[Story]:
        """Retrieve a specific story by ID"""
        matching = self._df[self._df['id'] == story_id]
        if matching.empty:
            return None
        return self._row_to_story(matching.iloc[0])
    
    def get_stories_by_risk_level(self, risk_level: str) -> List[Story]:
        """Retrieve stories filtered by risk level"""
        # Map risk_level to risk_label in NeoDataset
        # risk_level can be "Low", "Medium", "High"
        # risk_label in NeoDataset is "SAFE" or "RISK"
        
        if risk_level.lower() in ['low', 'safe']:
            filtered = self._df[self._df['risk_label'] == 'SAFE']
        elif risk_level.lower() in ['high', 'risk']:
            filtered = self._df[self._df['risk_label'] == 'RISK']
        else:  # Medium - return subset of RISK stories
            filtered = self._df[self._df['risk_label'] == 'RISK']
        
        return [self._row_to_story(row) for _, row in filtered.iterrows()]
    
    def get_story_count(self) -> int:
        """Get total number of stories"""
        return len(self._df)

